import os
import json
import hashlib
import streamlit as st
from streamlit.components.v1 import html as st_html
from dotenv import load_dotenv
from langchain.agents import initialize_agent, AgentType
from langchain_community.chat_models import ChatOpenAI
from langchain.prompts import ChatPromptTemplate
from langchain.chains import LLMChain

from utils.rag_utils import (
    load_vectorstore,
    create_conversation_chain,
    build_vectorstore_from_pdf,
)
from utils.rent_tools import (
    calculate_rent,
    calculate_moveout_date,
    get_repair_responsibility,
)

# ============== åˆå§‹åŒ–é…ç½® ==============
load_dotenv()
st.set_page_config(page_title="Tenant Chat | Smart Rental", page_icon="ğŸ’¬", layout="wide")

# ğŸš« å®Œå…¨ç¦ç”¨ä¾§è¾¹å¯¼èˆªæ 
st.markdown("""
    <style>
    /* éšè—æ•´ä¸ªä¾§è¾¹å¯¼èˆªå®¹å™¨ */
    [data-testid="stSidebarNav"], 
    [data-testid="stSidebarNavLink"],
    [data-testid="stSidebarNavSection"],
    [data-testid="stSidebarHeader"] {
        display: none !important;
        visibility: hidden !important;
    }

    /* è°ƒæ•´ä¾§è¾¹æ å®½åº¦ï¼Œåªä¿ç•™è‡ªå®šä¹‰çš„ç”¨æˆ·ä¿¡æ¯ */
    [data-testid="stSidebar"] {
        width: 220px !important;
    }
    </style>
""", unsafe_allow_html=True)

# ============== ç™»å½•æ ¡éªŒ ==============
if st.session_state.get("user_role") != "tenants":
    st.warning("Please log in as a tenant to access this page.")
    st.switch_page("app.py")

# ============== ä¾§è¾¹æ ï¼šç”¨æˆ·ä¿¡æ¯ä¸é…ç½® ==============
with st.sidebar:
    username = st.session_state.get("username", "Unknown User")
    st.markdown(f"ğŸ‘‹ **Current User: {username}**")

    # ç™»å‡ºæŒ‰é’®
    if st.button("ğŸšª Logout", use_container_width=True):
        st.session_state.clear()
        st.switch_page("app.py")

    st.markdown("---")

    # API Key çŠ¶æ€
    api_key = os.getenv("OPENAI_API_KEY") or st.session_state.get("openai_key")
    if api_key:
        st.success("âœ… Detected OpenAI API Key")
    else:
        key_input = st.text_input("ğŸ”‘ Enter OpenAI API Key", type="password")
        if key_input:
            os.environ["OPENAI_API_KEY"] = key_input
            st.session_state["openai_key"] = key_input
            st.success("âœ… API Key saved")

    st.markdown("---")

# ============== å·¥å…·å‡½æ•° ==============
def _file_sha1(uploaded_file) -> str:
    data = uploaded_file.getvalue() if hasattr(uploaded_file, "getvalue") else uploaded_file.read()
    return hashlib.sha1(data).hexdigest()

def rebuild_pipeline_from_loaded_contracts():
    """ä¿®å¤ç‰ˆçš„å‘é‡åº“é‡å»ºå‡½æ•°"""
    vs_values = list(st.session_state.vectorstores_map.values())
    if not vs_values:
        st.session_state.conversation_chain = None
        st.session_state.chain_invoke_safe = None
        st.session_state.agent = None
        st.info("ğŸ“­ No contracts loaded")
        return

    try:
        # ç®€å•çš„åˆå¹¶ç­–ç•¥ï¼šåªä½¿ç”¨ç¬¬ä¸€ä¸ªå‘é‡åº“
        if len(vs_values) > 0:
            merged_vs = vs_values[0]
            st.success(f"âœ… Loaded contracts with retrieval functionality")
        else:
            st.warning("âš ï¸ No available vector stores")
            return

        # é‡å»ºå¯¹è¯é“¾
        chain, llm, memory, chain_invoke_safe = create_conversation_chain(
            merged_vs, openai_api_key=os.getenv("OPENAI_API_KEY")
        )
        
        st.session_state.conversation_chain = chain
        st.session_state.chain_invoke_safe = chain_invoke_safe
        st.session_state.llm = llm
        st.session_state.memory = memory
        
        # é‡å»ºAgent
        tools = [calculate_rent, calculate_moveout_date, get_repair_responsibility]
        agent = initialize_agent(
            tools=tools,
            llm=llm,
            agent=AgentType.STRUCTURED_CHAT_ZERO_SHOT_REACT_DESCRIPTION,
            verbose=True,  # å¼€å¯è¯¦ç»†æ—¥å¿—ç”¨äºè°ƒè¯•
            memory=memory,
            handle_parsing_errors=True
        )
        st.session_state.agent = agent
        st.success("ğŸ¤– Agent initialized successfully")
        
    except Exception as e:
        st.error(f"âŒ Pipeline reconstruction failed: {e}")

def scroll_to_bottom():
    st_html(
        """
        <script>
            var chatDiv = window.parent.document.querySelector('.main');
            if (chatDiv) { chatDiv.scrollTop = chatDiv.scrollHeight; }
        </script>
        """,
        height=0
    )

# ============== åˆå§‹åŒ–çŠ¶æ€ ==============
defaults = {
    "chat": [],
    "vectorstores_map": {},
    "loaded_keys": set(),
    "conversation_chain": None,
    "chain_invoke_safe": None,
    "agent": None,
    "current_contract_link": None,  # å½“å‰åˆåŒçš„äº‘ç«¯é“¾æ¥
    "current_contract_qr": None,    # å½“å‰åˆåŒçš„äºŒç»´ç è·¯å¾„
    "current_contract_id": None     # å½“å‰åˆåŒçš„ID
}
for k, v in defaults.items():
    if k not in st.session_state:
        st.session_state[k] = v

# é¡¶éƒ¨å“ç‰Œ
st.markdown("""
<div style="background:#2E8B57;padding:12px 16px;border-radius:12px;margin-bottom:16px;">
  <h3 style="color:#fff;margin:0;">ğŸ’¬ Tenant Smart Assistant</h3>
</div>
""", unsafe_allow_html=True)

# ============== å·¦å³å¸ƒå±€ ==============
col_left, col_right = st.columns([1.15, 2], gap="large")

# ---------------- å·¦ä¾§ï¼šåˆåŒç®¡ç† ----------------
with col_left:
    st.markdown("### ğŸ“‚ Contract Management")

    contract_id = st.text_input("Enter Lease ID (e.g., MSH2025-001)")
    if st.button("ğŸ“¥ Load Database Contract", use_container_width=True):
        cid = contract_id.strip()
        if not cid:
            st.info("âš ï¸ Please enter a lease ID before loading.")
        else:
            db_path = os.path.join("db", cid)
            if not os.path.isdir(db_path):
                st.error("âŒ Lease ID not found.")
            else:
                # æ£€æŸ¥æ–°åˆåŒçš„äº‘ç«¯é“¾æ¥ä¿¡æ¯
                meta_path = os.path.join(db_path, "metadata.json")
                if os.path.exists(meta_path):
                    with open(meta_path, "r", encoding="utf-8") as f:
                        meta = json.load(f)
                        # å¦‚æœæ–°åˆåŒæœ‰äº‘ç«¯é“¾æ¥ï¼Œæ›´æ–°å¿«é€Ÿè®¿é—®
                        if meta.get("cloud_link"):
                            st.session_state.current_contract_link = meta["cloud_link"]
                            st.session_state.current_contract_id = cid
                            if meta.get("qr_code"):
                                qr_path = os.path.join(db_path, meta["qr_code"])
                                if os.path.exists(qr_path):
                                    st.session_state.current_contract_qr = qr_path
                            st.success("âœ… Quick access link updated")
                        else:
                            # å¦‚æœæ–°åˆåŒæ²¡æœ‰äº‘ç«¯é“¾æ¥ï¼Œæ¸…é™¤å¿«é€Ÿè®¿é—®
                            st.session_state.current_contract_link = None
                            st.session_state.current_contract_id = None
                            st.session_state.current_contract_qr = None
                            if "current_contract_link" in st.session_state and st.session_state.current_contract_link:
                                st.info("â„¹ï¸ New contract has no cloud link, quick access cleared.")
                
                key = f"db:{cid}"
                if key in st.session_state.loaded_keys:
                    st.info("Contract already loaded, skipping.")
                else:
                    with st.spinner("Loading contract..."):
                        try:
                            vs = load_vectorstore(db_path, os.getenv("OPENAI_API_KEY"))
                            st.session_state.vectorstores_map[key] = vs
                            st.session_state.loaded_keys.add(key)
                            rebuild_pipeline_from_loaded_contracts()
                            st.success(f"âœ… Database contract loaded: {cid}")
                        except Exception as e:
                            st.error(f"âŒ Loading failed: {e}")

    # æ˜¾ç¤ºå½“å‰åŠ è½½åˆåŒçš„äº‘ç«¯é“¾æ¥å’ŒäºŒç»´ç 
    if st.session_state.current_contract_link:
        st.markdown("---")
        st.markdown("### ğŸ“± Current Contract Quick Access")
        st.info(f"**Current Contract: ** {st.session_state.current_contract_id}")
        cols = st.columns([2, 1])
        with cols[0]:
            st.markdown(f"**Cloud Link: **\n{st.session_state.current_contract_link}")
        if st.session_state.current_contract_qr:
            with cols[1]:
                st.image(st.session_state.current_contract_qr, caption="Scan to Access Contract")


    st.markdown("---")
    st.subheader("ğŸ“ Upload My Contract PDF")
    up = st.file_uploader("Select PDF file", type=["pdf"])
    if up and st.button("ğŸ“„ Parse PDF Contract", use_container_width=True):
        sha1 = _file_sha1(up)
        up_key = f"upload:{sha1}:{getattr(up, 'size', 0)}"
        if up_key in st.session_state.loaded_keys:
            st.info("This PDF is already loaded, skipping.")
        else:
            with st.spinner("Parsing and building index..."):
                try:
                    vs = build_vectorstore_from_pdf(up, openai_api_key=os.getenv("OPENAI_API_KEY"))
                    st.session_state.vectorstores_map[up_key] = vs
                    st.session_state.loaded_keys.add(up_key)
                    rebuild_pipeline_from_loaded_contracts()
                    st.success(f"âœ… Custom contract loaded: {up.name}")
                except Exception as e:
                    st.error(f"âŒ Parsing failed: {e}")

   # ---------------- Current Loaded Contracts Display ----------------
    st.markdown("### ğŸ“„ Current Loaded Contracts")

    if st.session_state.vectorstores_map:
        delete_keys = []  # è®°å½•è¦åˆ é™¤çš„é”®

        for key in list(st.session_state.vectorstores_map.keys()):
            # åˆ¤æ–­æ¥æºä¸æ˜¾ç¤ºå
            if key.startswith("db:"):
                source = "ğŸ“ Database"
                name = key.replace("db:", "")
            elif key.startswith("upload:"):
                source = "ğŸ“ Uploaded File"
                name = f"{key.split(':')[1][:8]}..."  # ç”¨ SHA1 çš„å‰å‡ ä½ä»£æ›¿
            else:
                source = "â“ Other"
                name = key

            # æ¯ä¸€è¡Œæ˜¾ç¤º
            cols = st.columns([2, 3, 1])
            with cols[0]:
                st.markdown(f"**{source}**")
            with cols[1]:
                st.markdown(name)
            with cols[2]:
                if st.button("âŒ", key=f"del_{key}", use_container_width=True):
                    delete_keys.append(key)

        # æ‰§è¡Œåˆ é™¤æ“ä½œ
        if delete_keys:
            for k in delete_keys:
                if k in st.session_state.vectorstores_map:
                    del st.session_state.vectorstores_map[k]
                st.session_state.loaded_keys.discard(k)
            rebuild_pipeline_from_loaded_contracts()
            st.rerun()

        st.success(f"âœ… Current contract count: {len(st.session_state.vectorstores_map)}")
    else:
        st.info("ğŸ“­ No loaded contracts. You can load from the database or upload a PDF file.")

    # Add debugging information section
    st.markdown("---")
    st.markdown("### ğŸ”§ Debug Information")

    # æ˜¾ç¤ºå½“å‰çŠ¶æ€
    st.write(f"Loaded contract count: {len(st.session_state.vectorstores_map)}")
    st.write(f"Conversation Chain: {'âœ…' if st.session_state.conversation_chain else 'âŒ'}")
    st.write(f"Agent: {'âœ…' if st.session_state.agent else 'âŒ'}")
    st.write(f"Chain Invoke Safe: {'âœ…' if st.session_state.chain_invoke_safe else 'âŒ'}")
    
    # æµ‹è¯•æ£€ç´¢åŠŸèƒ½æŒ‰é’®
    if st.button("ğŸ§ª Test Retrieval", key="test_retrieval"):
        if st.session_state.vectorstores_map:
            vs = list(st.session_state.vectorstores_map.values())[0]
            test_results = vs.similarity_search("Rent", k=2)
            st.success(f"Found {len(test_results)} relevant snippets")
            for i, doc in enumerate(test_results):
                st.write(f"**Result {i+1}:** {doc.page_content[:100]}...")
        else:
            st.warning("No available vector stores to test.")


# ---------------- å³ä¾§ï¼šæ™ºèƒ½é—®ç­” ----------------
with col_right:
    # æ ‡é¢˜ + æ¸…ç©ºæŒ‰é’®
    col1, col2 = st.columns([6, 1])
    with col1:
        st.markdown("### ğŸ’¬ğŸ’¬ Intelligent Q&A")
    with col2:
        if st.button("ğŸ—‘ğŸ—‘ï¸", help="Clear chat history"):
            st.session_state.chat = []
            st.rerun()

    # èŠå¤©å†…å®¹å®¹å™¨
    chat_container = st.container()
    with chat_container:
        for role, text in st.session_state.chat:
            with st.chat_message("user" if role == "user" else "assistant"):
                st.markdown(text)
    scroll_to_bottom()

    # å›ºå®šè¾“å…¥æ¡†
    st.markdown(
        """
        <style>
            .stChatInputContainer {
                position: fixed !important;
                bottom: 1rem !important;
                width: 58% !important;
                right: 1rem !important;
                z-index: 999;
                background: white;
                padding-top: 0.5rem;
                border-top: 1px solid #ddd;
            }
        </style>
        """,
        unsafe_allow_html=True
    )

    q = st.chat_input("Please enter your question (You can ask directly without loading the contract first.)")

    if q:
        st.session_state.chat.append(("user", q))
        with st.chat_message("user"):
            st.markdown(q)
        scroll_to_bottom()

        with st.chat_message("assistant"):
            thinking = st.empty()
            thinking.markdown("ğŸ¤”ğŸ¤” Thinking...")
            
            # ========== è°ƒè¯•ä¿¡æ¯ ==========
            debug_info = st.empty()
            debug_info.info(f"""
            **Debug Information**
            - Loaded contracts: {len(st.session_state.vectorstores_map)} items
            - RAG Chain: {'âœ…' if st.session_state.chain_invoke_safe else 'âŒ'}
            - Agent: {'âœ…' if st.session_state.agent else 'âŒ'}
            """)

            reply = ""
            contract_info = ""

            # 1ï¸âƒ£ å°è¯• RAG
            if st.session_state.chain_invoke_safe:
                try:
                    debug_info.info("ğŸ” Processing...")
                    res = st.session_state.chain_invoke_safe({"question": q})
                    contract_info = res.get("answer", "")
                    debug_info.success(f"âœ… Retrieval complete, information length: {len(contract_info)}")

                    if res.get("source_documents"):
                        debug_info.write(f"ğŸ“„ Found {len(res['source_documents'])} relevant document snippets")
                        for i, doc in enumerate(res["source_documents"][:2]):
                            debug_info.write(f"Snippet {i+1}: {doc.page_content[:100]}...")
                except Exception as e:
                    debug_info.error(f"âŒ RAG retrieval failed: {e}")
                    contract_info = ""
            else:
                debug_info.warning("âš ï¸ RAG chain not initialized, using generic response")

            # 2ï¸âƒ£ åˆ¤æ–­æ˜¯å¦è°ƒç”¨å·¥å…·
            intent = "NO"
            try:
                debug_info.info("ğŸ¤– Analyzing user intent...")
                intent_llm = ChatOpenAI(model_name="gpt-4o-mini", temperature=0, openai_api_key=os.getenv("OPENAI_API_KEY"))
                prompt = ChatPromptTemplate.from_messages([
                    ("system", "Judge whether the user needs to calculate rent, termination time, or maintenance responsibilities. If so, answer YES, otherwise answer NO."),
                    ("human", "{q}")
                ])
                ic_chain = LLMChain(llm=intent_llm, prompt=prompt)
                intent = ic_chain.run({"q": q}).strip().upper()
                debug_info.info(f"Intent analysis result: {intent}")
            except Exception:
                debug_info.warning("Intent analysis failed, defaulting to NO")

            # 3ï¸âƒ£ è°ƒç”¨ Agentï¼ˆè‹¥éœ€è¦å·¥å…·ï¼‰
            if intent == "YES" and st.session_state.agent:
                try:
                    debug_info.info("ğŸš€ Invoking Agent...")
                    fused = (
                        f"Answer the question based on the following information: \n\n"
                        f"ã€Contract Informationã€‘\n{contract_info}\n\n"
                        f"ã€User Questionã€‘{q}\n\n"
                        f"If calculation is needed, please infer rent, lease term, etc. from the contract and call the appropriate tool."
                    )
                    result = st.session_state.agent.invoke({"input": fused})
                    reply = (
                        result.get("output")
                        or result.get("answer")
                        or result.get("result")
                        or str(result)
                    )
                    reply = reply.split("Observation:")[-1].strip()
                    debug_info.success("âœ… Agent response complete")
                except Exception as e:
                    debug_info.error(f"âŒ Agent invocation failed: {e}")
                    reply = ""

            # 4ï¸âƒ£ æ—  Agent â†’ æ™®é€š LLM
            if not reply:
                try:
                    debug_info.info("ğŸ’­ Using generic LLM...")
                    llm = ChatOpenAI(model_name="gpt-4o-mini", temperature=0.2, openai_api_key=os.getenv("OPENAI_API_KEY"))
                    prompt = ChatPromptTemplate.from_messages([
                        ("system", "You are a rental assistant. Please provide the final answer directly without showing the thought process."),
                        ("human", f"{q}\n\n(Contract context, if any): {contract_info}")
                    ])
                    ans_chain = LLMChain(llm=llm, prompt=prompt)
                    reply = ans_chain.run({"q": q})
                    debug_info.success("âœ… LLM response complete")
                except Exception as e:
                    debug_info.error(f"âŒ LLM invocation failed: {e}")
                    reply = "Sorry, I encountered an error while processing your request."

            # æ¸…é™¤è°ƒè¯•ä¿¡æ¯ï¼Œæ˜¾ç¤ºæœ€ç»ˆå›ç­”
            debug_info.empty()
            thinking.empty()
            st.markdown(reply)
            scroll_to_bottom()

        st.session_state.chat.append(("assistant", reply))
        st.rerun()